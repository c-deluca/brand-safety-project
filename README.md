# brand-safety-project

# ğŸ›¡ï¸ Brand Safety

Il progetto **Brand Safety** ha l'obiettivo di identificare la presenza di **scene violente o disturbanti** all'interno di video provenienti dalla **medialibrary di Repubblica**.

---

## ğŸ¯ Obiettivo

Data una lista di URL video (medialibrary), il sistema:

- Analizza automaticamente il contenuto dei video.
- Rileva la presenza di elementi **violenti o disturbanti**.
- Classifica le scene problematiche secondo le **categorie GARM** (Global Alliance for Responsible Media), fornite da Manzoni.
- Restituisce un output strutturato in **JSON** e **CSV** contenente:
  - `flag` = 1 se viene rilevato almeno un contenuto sensibile, 0 altrimenti.
  - Le **categorie di disturbo rilevate** (massimo 3 per video).

---

## ğŸ“¥ Input

- Una lista di **link video** della medialibrary.
- I video sono scaricati o processati automaticamente.

---

## ğŸ“¤ Output

Per ogni video analizzato, vengono generati:

- `output.json`: file JSON con il dettaglio delle analisi.
- `output/.csv`: tabella con:
  - `video_id`
  - `flag` (0 o 1)
  - `categorie` (max 3, separate da virgola)

---

## ğŸ—‚ï¸ Struttura del progetto

    <br>

    <!-- TREEVIEW START -->
    ```bash
    â”œâ”€â”€ check_url_availability.py --controlla preliminarmente quanti video sono ancora disponibili
    â”œâ”€â”€ data/
    â”‚   â””â”€â”€ [lista di url tvmanager]
    â”œâ”€â”€ prompt.txt   
    â”œâ”€â”€ output/
    â”‚   â”œâ”€â”€ [generated_output.csv]
    â”‚   â””â”€â”€ [generated_output.json]
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â””â”€â”€ src/
        â”œâ”€â”€ conf 
        â”œâ”€â”€ extraction -- in caso di estrazione link tvmanager da link html
        â”œâ”€â”€ query -- in caso di estrazione link html da cms
        â”œâ”€â”€ utils.py
        â””â”€â”€ main.py
    ```

    <!-- TREEVIEW END -->


## âš™ï¸ Per avviare lâ€™analisi:

python src/main.py

